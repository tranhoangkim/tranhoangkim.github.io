<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Kim Tran</title>

    <meta name="author" content="Kim Tran">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:1000px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:1.5%;width:72%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Kim Tran
                </p>
                <p>
    I am currently a Master's student in <a href="https://engineering.uark.edu/electrical-engineering-computer-science/">Computer Science at the University of Arkansas</a>, advised by <a href="https://engineering.uark.edu/electrical-engineering-computer-science/electrical-engineering-faculty/uid/jgauch/name/John+Michael+Gauch/">Prof. John Gauch</a> and <a href="https://scholar.google.com/citations?user=8ck0k_UAAAAJ&hl=en">Prof. Ngan Le</a> in the areas of computer vision and computer graphics. Prior to my master's, I was an AI Research Resident at <a href="https://fpt.com/en/news/fpt-news/fpt-software-ai-center">FPT AI Center</a>, where I had the privilege of working closely with Prof. Ngan Le. I earned my bachelor's degree in Computer Science from <a href="https://en.hcmus.edu.vn">National University, University of Science, Vietnam</a>.<br>
    In the summer of 2025, I interned at <a href="https://www.linkedin.com/company/koidra/posts/?feedView=all">Koidra</a>, Seattle, as a Physics-Informed Machine Learning Researcher, where I worked directly with <a href="https://www.linkedin.com/in/ktran/">Dr. Kenneth Tran</a>, the CTO of Koidra and former Principal Research Scientist at Microsoft — to develop digital twins for greenhouses that simulate air temperature, vapor pressure, and energy consumption.
                </p>
                <p style="text-align:center">
                  <a href="mailto:tranhoangkim981@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://drive.google.com/file/d/16uGqMiUSnbhc2I80ePz3e1CvyFp8jHEs/view?usp=sharing">Resume</a> &nbsp;/&nbsp;
                  <a href="https://leetcode.com/u/tranhoangkim981/">Leetcode</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=SQXHftAAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/kim-tran-766363244/">Linkedin</a> &nbsp;/&nbsp;
                  <a href="https://github.com/tranhoangkim?tab=repositories">Github</a>
                </p>
              </td>
              <td style="padding:1.5%;width:28%;max-width:28%">
                <a href="images/kimtran.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/kimtran.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p style="margin-bottom: 20px;">
                 My motivation for doctoral research stems from a compelling challenge: while reinforcement learning has achieved remarkable successes in simulated domains (e.g. games and robotics simulators), <strong>most real-world control problems cannot rely on unlimited data or perfect simulators</strong>. Motivated by this, my research interests lie at the intersection of model-based reinforcement learning, physics-informed modeling, graph neural networks, and control systems, with a focus on enabling intelligent agents to operate safely and efficiently in real-world environments with <strong>limited data</strong>. I am curious about three key questions:
                </p>
                <p style="margin-bottom: 12px; margin-left: 20px;">
                  • How can reinforcement learning be applied across diverse practical domains such as industrial automation, education, healthcare, and aerospace—beyond the current emphasis on LLMs and robotics?
                </p>
                <p style="margin-bottom: 20px; margin-left: 20px;">
                  • How can multi-modality (drawing from my background in vision-language models and 3D geometry) be effectively integrated into reinforcement learning to enhance perception and decision-making?
                </p>
                <p style="margin-bottom: 20px; margin-left: 20px;">
                  • How can we bridge the gap between simulation and reality in real-world control problems with limited data?
                </p>
                <p style="margin-bottom: 20px;">
                  My long-term goal through a PhD program, is to create <strong>adaptive, interpretable, and generalizable reinforcement learning frameworks </strong> that can be applied to complex and practical domains and advance the foundation of learning-based control and its integration with physics-based models, perception and graph-structured representations for real-world decision-making.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:6px;"><tbody>
            <tr>
              <td>
                <h2>Publications</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 20px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr onmouseout="bolt3d_stop()" onmouseover="bolt3d_start()"  bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='bolt3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/bolt3d.mp4" type="video/mp4">
          Your browser does not support the video tag.

          </video></div>
          <img src='images/bolt3d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function bolt3d_start() {
            document.getElementById('bolt3d_image').style.opacity = "1";
          }

          function bolt3d_stop() {
            document.getElementById('bolt3d_image').style.opacity = "0";
          }
          bolt3d_stop()
        </script>
      </td>
      <td style="padding:12px;width:80%;vertical-align:middle">
        <a href="https://szymanowiczs.github.io/bolt3d">
          <span class="papertitle">Bolt3D: Generating 3D Scenes in Seconds</span>
        </a>
        <br>
        <a href="https://szymanowiczs.github.io/">Stanislaw Szymanowicz</a>,
        <a href="https://jasonyzhang.com">Jason Y. Zhang</a>,
        <a href="https://pratulsrinivasan.github.io">Pratul Srinivasan</a>,
        <a href="https://ruiqigao.github.io">Ruiqi Gao</a>,
        <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>,
        <a href="https://holynski.org">Aleksander Holynski</a>,
        <a href="https://ricardomartinbrualla.com">Ricardo Martin-Brualla</a>,
		<strong>Jonathan T. Barron</strong>,
        <a href="https://henzler.github.io">Philipp Henzler</a>
        <br>
        <em>ICCV</em>, 2025
        <br>
        <a href="https://szymanowiczs.github.io/bolt3d">project page</a>
        /
        <a href="https://szymanowiczs.github.io/bolt3d">arXiv</a>
        <p></p>
        <p>
		By training a latent diffusion model to directly output 3D Gaussians we enable fast (~6 seconds on a single GPU) feed-forward 3D scene generation.
        </p>
      </td>
    </tr>

    <tr onmouseout="ever_stop()" onmouseover="ever_start()">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='ever_image'>
					  <img src='images/ever_after.png' width=100%>
					</div>
          <img src='images/ever_before.png' width=100%>
        </div>
        <script type="text/javascript">
          function ever_start() {
            document.getElementById('ever_image').style.opacity = "1";
          }

          function ever_stop() {
            document.getElementById('ever_image').style.opacity = "0";
          }
          ever_stop()
        </script>
      </td>
      <td style="padding:12px;width:80%;vertical-align:middle">
        <a href="https://half-potato.gitlab.io/posts/ever/">
			<span class="papertitle">EVER: Exact Volumetric Ellipsoid Rendering for Real-time View Synthesis
</span>
        </a>
        <br>
				<a href="https://half-potato.gitlab.io/">Alexander Mai</a>, 
				<a href="https://phogzone.com/">Peter Hedman</a>,
				<a href="https://grgkopanas.github.io/">George Kopanas</a>,
        <a href="https://dorverbin.github.io/">Dor Verbin</a>,
        <a href="https://scholar.google.com/citations?user=ozNFrecAAAAJ&hl=en">David Futschik</a>,
        <a href="https://xharlie.github.io/">Qiangeng Xu</a>,
        <a href="https://jacobsschool.ucsd.edu/faculty/profile?id=253">Falko Kuester</a>,
				<strong>Jonathan T. Barron</strong>,
        <a href="https://www.zhangyinda.com/">Yinda Zhang</a>
				<br>
        <em>ICCV</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://half-potato.gitlab.io/posts/ever/">project page</a>
        /
        <a href="https://arxiv.org/abs/2410.01804">arXiv</a>
        <p></p>
        <p>
				Raytracing constant-density ellipsoids yields more accurate and flexible radiance fields than splatting Gaussians, and still runs in real-time.
        </p>
      </td>
    </tr>


    <tr onmouseout="cat4d_stop()" onmouseover="cat4d_start()" bgcolor="#ffffd0">
      <td style="padding:16px;width:20%;vertical-align:middle">
        <div class="one">
          <div class="two" id='cat4d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/cat4d.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/cat4d.jpg' width="160">
        </div>
        <script type="text/javascript">
          function cat4d_start() {
            document.getElementById('cat4d_image').style.opacity = "1";
          }

          function cat4d_stop() {
            document.getElementById('cat4d_image').style.opacity = "0";
          }
          cat4d_stop()
        </script>
      </td>
      <td style="padding:12px;width:80%;vertical-align:middle">
        <a href="https://cat-4d.github.io/">
			<span class="papertitle">CAT4D: Create Anything in 4D with Multi-View Video Diffusion Models
</span>
        </a>
        <br>
				<a href="https://www.cs.columbia.edu/~rundi/">Rundi Wu</a>,
				<a href="https://ruiqigao.github.io/">Ruiqi Gao</a>,
				<a href="https://poolio.github.io/">Ben Poole</a>,
				<a href="https://alextrevithick.github.io/">Alex Trevithick</a>,
				<a href="https://www.cs.columbia.edu/~cxz/index.htm/">Changxi Zheng</a>,
				<strong>Jonathan T. Barron</strong>,
				<a href="https://holynski.org/">Aleksander Holynski</a>
        <br>
        <em>CVPR</em>, 2025 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
        <br>
        <a href="https://cat-4d.github.io/">project page</a>
        /
        <a href="https://arxiv.org/abs/2411.18613">arXiv</a>
        <p></p>
        <p>
				An approach for turning a video into a 4D radiance field that can be rendered in real-time. When combined with a text-to-video model, this enables text-to-4D.
        </p>
      </td>
    </tr>

        </td>
      </tr>
    </table>
  </body>
</html>
